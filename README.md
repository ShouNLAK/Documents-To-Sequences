# ğŸ“Š Document-to-Sequence Converter for Data Mining

> **Research-grade Java NLP pipeline** vá»›i **Interactive HTML Dashboard** - Transform raw text into ML-ready numerical sequences

[![Java](https://img.shields.io/badge/Java-11%2B-orange?style=for-the-badge&logo=java)](https://www.oracle.com/java/)
[![Build](https://img.shields.io/badge/Build-Passing-success?style=for-the-badge)](https://github.com)
[![License](https://img.shields.io/badge/License-MIT-blue?style=for-the-badge)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Production-green?style=for-the-badge)](https://github.com)

---

## ğŸ¯ What's New (Latest Version)

### âœ¨ **Enhanced UI/UX**
- ğŸ¨ **Modern Tab Design** - Beautiful animated tabs with icons (ğŸ“Š Matrix, ğŸ“– Vocabulary, ğŸ“„ Documents)
- ğŸ“Š **Visual Progress Bars** - IDF and TF-IDF values vá»›i gradient bars
- ğŸ¯ **Smart Highlighting** - Tá»± Ä‘á»™ng highlight important terms (IDF>1.5 hoáº·c TF-IDF>0.01)
- ğŸ’… **Professional Styling** - Monospace badges, gradient headers, smooth animations

### ğŸ”¬ **TF-IDF Calculation Fixed**
- âœ… **Smooth-IDF Formula** - `log((N+1)/(df+1)) + 1` theo chuáº©n sklearn
- âœ… **Document Frequency Column** - ThÃªm cá»™t Doc Freq trong báº£ng Vocabulary
- ğŸ“– **6-Column Vocabulary Table** - ID, Token, Doc Freq, Avg TF, IDF, Avg TF-IDF
- ğŸ“š **Full Documentation** - TFIDF_VERIFICATION.md vá»›i chi tiáº¿t cÃ´ng thá»©c

**References:**
- [GeeksforGeeks - Understanding TF-IDF](https://www.geeksforgeeks.org/understanding-tf-idf-term-frequency-inverse-document-frequency/)
- [Wikipedia - TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)

---

## ğŸ“š Table of Contents

- [Overview](#-overview)
- [Key Features](#-key-features)
- [Quick Start](#-quick-start)
- [Project Structure](#-project-structure)
- [Usage Examples](#-usage-examples)
- [HTML Dashboard](#-html-dashboard)
- [Output Files Explained](#-output-files-explained)
- [Pipeline Details](#-pipeline-details)
- [Configuration Guide](#-configuration-guide)
- [Technical Documentation](#-technical-documentation)
- [FAQ & Troubleshooting](#-faq--troubleshooting)

---

## ğŸŒŸ Overview

### What It Does

Transform unstructured text documents into **machine learning-ready numerical representations** through a comprehensive **7-stage NLP pipeline**:

```mermaid
Raw Text â†’ Clean â†’ Tokenize â†’ Filter â†’ Stem â†’ Encode â†’ Vectorize â†’ ML Models
   â†“        â†“         â†“         â†“       â†“        â†“         â†“
"Hello"  "hello"  ["hello"]   [âœ“]   ["hello"]  [42]   [0,0,1,...]
```

### Why Choose This?

| Feature | Description |
|---------|-------------|
| ğŸ“ **Research-Grade** | Based on scientific papers (GeeksforGeeks, Wikipedia) |
| ğŸ”¬ **Accurate TF-IDF** | Verified smooth-IDF formula `log((N+1)/(df+1)) + 1` |
| ğŸ¨ **Beautiful Dashboard** | Interactive HTML with modern UI (gradient tabs, visual bars) |
| ğŸš€ **Production-Ready** | Error handling, batch processing, 50+ files support |
| ğŸ“Š **Rich Visualization** | Frequency matrix, vocabulary stats, document comparison |
| ğŸ”§ **Highly Configurable** | Single file vs folder, custom preprocessing options |
| ğŸ“¥ **Multiple Outputs** | BoW, TF-IDF, Integer Sequences, CSV export |
| ğŸ’» **Cross-Platform** | Windows (build.bat), Linux/Mac (build.sh) |

---

## ğŸ Key Features

### ğŸ”„ **Complete NLP Pipeline (7 Steps)**

1. **Text Preprocessing** - Cleaning, normalization, case conversion
2. **Tokenization** - Word-level splitting with configurable min length
3. **Stop Word Filtering** - 127 English stop words removal
4. **Porter Stemming** - Intelligent stemming preserving word meaning
5. **Vocabulary Construction** - Token-to-index mapping with frequency thresholds
6. **Integer Encoding** - Sequence representation with special tokens (<PAD>, <UNK>)
7. **Vectorization** - Bag-of-Words and TF-IDF with L2 normalization

### ğŸ“Š **Interactive HTML Dashboard**

#### ğŸ¨ **Modern Tab Navigation**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š Frequency Matrix  â”‚  ğŸ“– Vocabulary  â”‚  ğŸ“„ Docs â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Features:**
- âœ… **Animated Tabs** - Icon scaling, gradient underline, smooth transitions
- âœ… **Sticky Headers** - Table headers stay visible while scrolling
- âœ… **Hover Effects** - Blue highlight, button lift animation
- âœ… **Pagination** - 10 docs/page (Matrix), 50 tokens/page (Vocabulary)
- âœ… **Disabled States** - Auto-disable Prev/Next at boundaries
- âœ… **CSV Export** - Download Matrix or Vocabulary with full data

#### ğŸ“– **Enhanced Vocabulary Table (6 Columns)**

| ID | Token | Doc Freq | Avg TF | IDF | Avg TF-IDF |
|----|-------|----------|--------|-----|------------|
| 2 | `add` | 50 | 0.0095 | 1.00 â–°â–°â–°â–°â–± | 0.0536 â–°â–°â–°â–± |
| 15 | `cleaners` | 35 | 0.0124 | **1.35** â–°â–°â–°â–°â–°â–°â–± | **0.0642** â–°â–°â–°â–°â–°â–± |

**Visual Elements:**
- ğŸ“Š **Progress Bars** - Width proportional to max IDF/TF-IDF
- ğŸ¯ **Highlighting** - Yellow background for important terms
- ğŸ’… **Token Badges** - Monospace font with gray background
- ğŸ”¢ **Monospace Numbers** - Easy to read and align

#### ğŸ“„ **Document Viewer**

- **Original Text** - Raw input with formatting preserved
- **Preprocessed Text** - Cleaned, stemmed tokens
- **Toggle View** - Radio buttons to switch between versions
- **Multiple Documents** - First 50 documents shown with pagination

### ğŸ”¬ **Accurate TF-IDF Implementation**

**Formula (Smooth-IDF):**
```
TF(t,d) = count(t in d) / total_terms(d)

IDF(t) = log((N + 1) / (df(t) + 1)) + 1

TF-IDF(t,d) = TF(t,d) Ã— IDF(t)

# Then L2 Normalization:
norm = sqrt(Î£ tfidfÂ²)
normalized_tfidf = tfidf / norm
```

**Verification:**
- âœ… Matches sklearn `TfidfVectorizer` with `smooth_idf=True`
- âœ… Validated against GeeksforGeeks & Wikipedia formulas
- âœ… See `TFIDF_VERIFICATION.md` for detailed calculations

### ğŸš€ **Batch Processing**

Process **entire folders** automatically:
```bash
.\build.bat auto
# Processes all .txt files in Data/Input/
# Generates unified report.html
```

**Features:**
- ğŸ“‚ Auto-detect all `.txt` files
- ğŸ“Š Unified frequency matrix (all documents)
- ğŸ“ˆ Combined vocabulary statistics
- ğŸ¯ 50+ documents support with pagination

---

## ğŸš€ Quick Start

### Prerequisites

- **Java 11+** (download from [oracle.com](https://www.oracle.com/java/technologies/downloads/))
- Text files with your documents

### 3-Step Setup

#### **Step 1: Prepare Input**

Create `Data/Input/input.txt`:
```text
Natural Language Processing (NLP) is a fascinating field.
It combines computer science, artificial intelligence, and linguistics.
Text mining helps extract valuable insights from unstructured data.
```

Or place **multiple files** (`input01.txt`, `input02.txt`, ...):
```
Data/Input/
â”œâ”€â”€ input01.txt
â”œâ”€â”€ input02.txt
â”œâ”€â”€ input03.txt
â””â”€â”€ ...
```

#### **Step 2: Run Pipeline**

**Option A: Auto Mode (Recommended)** - Batch processing
```bash
.\build.bat auto         # Windows
./build.sh auto          # Linux/Mac
```

**Option B: Interactive Mode** - Single file with prompts
```bash
.\build.bat run
```

**Option C: Build Only**
```bash
.\build.bat              # Compile without running
```

#### **Step 3: View Results**

Open `Data/Output/report.html` in your browser ğŸ‰

---

## ğŸ“ Project Structure

```
DocumentToSequences/
â”‚
â”œâ”€â”€ ğŸ“‚ Data/
â”‚   â”œâ”€â”€ Input/                      â† Your text files
â”‚   â”‚   â”œâ”€â”€ input.txt              â† Single file mode
â”‚   â”‚   â”œâ”€â”€ input01.txt            â† Batch mode
â”‚   â”‚   â”œâ”€â”€ input02.txt
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ Output/                     â† Generated results
â”‚       â”œâ”€â”€ output_sequences.txt   â† Integer sequences + tokens
â”‚       â”œâ”€â”€ output_bow_vectors.txt â† Bag-of-Words vectors
â”‚       â”œâ”€â”€ output_tfidf_vectors.txt â† TF-IDF vectors
â”‚       â”œâ”€â”€ output_numeric.txt     â† Pure number sequences
â”‚       â””â”€â”€ report.html            â† ğŸŒŸ Interactive dashboard
â”‚
â”œâ”€â”€ ğŸ“‚ src/main/java/com/example/sequencer/
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ core/
â”‚   â”‚   â”œâ”€â”€ DocumentSequencerApplication.java  â† Main interactive app
â”‚   â”‚   â””â”€â”€ AutoRunner.java                    â† Batch processor
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ preprocessing/
â”‚   â”‚   â”œâ”€â”€ TextPreprocessor.java    â† Text cleaning
â”‚   â”‚   â”œâ”€â”€ Tokenizer.java           â† Word splitting
â”‚   â”‚   â”œâ”€â”€ StopWordFilter.java      â† Stop word removal
â”‚   â”‚   â””â”€â”€ PorterStemmer.java       â† Stemming (intelligent)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ encoding/
â”‚   â”‚   â”œâ”€â”€ Vocabulary.java          â† Token-to-index mapping
â”‚   â”‚   â””â”€â”€ IntegerEncoder.java      â† Sequence encoding
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ vectorization/
â”‚   â”‚   â”œâ”€â”€ BagOfWordsVectorizer.java  â† BoW implementation
â”‚   â”‚   â””â”€â”€ TfidfVectorizer.java       â† TF-IDF (smooth-idf)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ model/
â”‚   â”‚   â”œâ”€â”€ DocumentSequence.java    â† Document representation
â”‚   â”‚   â””â”€â”€ SequenceVector.java      â† Vector representation
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“‚ pipeline/
â”‚   â”‚   â””â”€â”€ SequencingPipeline.java  â† 7-stage pipeline orchestrator
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“‚ io/
â”‚       â”œâ”€â”€ DocumentReader.java      â† File input handler
â”‚       â”œâ”€â”€ SequenceWriter.java      â† Text output writer
â”‚       â””â”€â”€ HtmlReportWriter.java    â† ğŸŒŸ HTML dashboard generator
â”‚
â”œâ”€â”€ ğŸ“‚ target/classes/               â† Compiled .class files
â”‚
â”œâ”€â”€ ğŸ“„ build.bat                     â† Windows build script
â”œâ”€â”€ ğŸ“„ build.sh                      â† Linux/Mac build script
â”œâ”€â”€ ğŸ“„ pom.xml                       â† Maven config (optional)
â”‚
â”œâ”€â”€ ğŸ“„ README.md                     â† This file
â”œâ”€â”€ ğŸ“„ TFIDF_VERIFICATION.md        â† TF-IDF formula verification
â”œâ”€â”€ ğŸ“„ VOCABULARY_ENHANCEMENTS.md   â† UI improvements log
â””â”€â”€ ğŸ“„ VOCAB_TABLE_GUIDE.txt        â† Quick reference card
```

---

## ğŸ’¡ Usage Examples

### Example 1: Single Document Processing

**Input:** `Data/Input/input.txt`
```text
Machine learning is transforming how we analyze data.
Natural language processing enables computers to understand human language.
Deep learning models achieve remarkable results in text classification.
```

**Run:**
```bash
.\build.bat auto
```

**Output:** `Data/Output/report.html`
```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“Š STATISTICS                                     â•‘
â•‘  Documents: 1                                     â•‘
â•‘  Vocabulary: 23 unique tokens                     â•‘
â•‘  Total Tokens: 19 (after filtering)               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“– VOCABULARY TABLE (Page 1 / 1)
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID â”‚   Token    â”‚ Doc Freq â”‚ Avg TF  â”‚ IDF  â”‚ Avg TFIDF  â”‚
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 2  â”‚  machine   â”‚    1     â”‚ 0.0526  â”‚ 1.69 â”‚  0.0892    â”‚
â”‚ 3  â”‚  learn     â”‚    2     â”‚ 0.1053  â”‚ 1.00 â”‚  0.1053    â”‚
â”‚ 4  â”‚  languag   â”‚    2     â”‚ 0.1053  â”‚ 1.00 â”‚  0.1053    â”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example 2: Batch Processing (50+ Files)

**Input:** `Data/Input/input01.txt` - `input50.txt`

**Run:**
```bash
.\build.bat auto
```

**Console Output:**
```
================================================================================
  AUTO RUNNER - BATCH DOCUMENT PROCESSING
================================================================================

Found 50 file(s) in Data/Input
  Reading: input01.txt
  Reading: input02.txt
  ...
Loaded total 50 document(s)

[Step 1/7] Text Preprocessing...
  âœ“ Completed: Applied cleaning and normalization

[Step 2/7] Tokenization...
  âœ“ Completed: Generated 26938 tokens

[Step 3/7] Stop Word Filtering...
  âœ“ Completed: Retained 22692 tokens

[Step 4/7] Stemming...
  âœ“ Completed: Applied Porter Stemmer

[Step 5/7] Vocabulary Construction & Integer Encoding...
Vocabulary built: 377 unique tokens (min_freq=1)
  âœ“ Completed: Encoded to integer sequences

[Step 6/7] Bag-of-Words Vectorization...
BoW vocabulary fitted: 375 unique features
  âœ“ Completed: Generated BoW vectors

[Step 7/7] TF-IDF Vectorization...
TF-IDF vocabulary fitted: 375 unique features
  âœ“ Completed: Generated TF-IDF vectors

================================================================================
COMPLETED! Results saved to Data/Output
ğŸ“Š Open: Data/Output/report.html
================================================================================
```

**HTML Report:**
- ğŸ“Š **Frequency Matrix**: 50 docs Ã— 377 tokens (paginated: 10 docs/page)
- ğŸ“– **Vocabulary**: 377 tokens with stats (paginated: 50 tokens/page)
- ğŸ“„ **Documents**: First 50 docs with Original/Preprocessed toggle

### Example 3: Custom Configuration

Edit `src/main/java/com/example/sequencer/core/AutoRunner.java`:

```java
PipelineConfiguration config = new PipelineConfiguration()
    .setLowercase(true)              // true | false
    .setRemoveStopWords(true)        // true | false
    .setApplyStemming(true)          // true | false
    .setMinFrequency(2)              // 1, 2, 3, ... (filter rare words)
    .setMinTokenLength(3);           // 1, 2, 3, ... (filter short words)
```

**Then rebuild:**
```bash
.\build.bat
.\build.bat auto
```

---

## ğŸ¨ HTML Dashboard

### Tab 1: ğŸ“Š Frequency Matrix

**What it shows:** Document-Term frequency matrix

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ Doc / ID â”‚  0  â”‚  1  â”‚  2  â”‚  3  â”‚ ...       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•ªâ•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Doc 1   â”‚  0  â”‚  0  â”‚  3  â”‚  5  â”‚ ...       â•‘
â•‘  Doc 2   â”‚  0  â”‚  0  â”‚  2  â”‚  1  â”‚ ...       â•‘
â•‘  Doc 3   â”‚  0  â”‚  0  â”‚  4  â”‚  2  â”‚ ...       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•§â•â•â•â•â•â•§â•â•â•â•â•â•§â•â•â•â•â•â•§â•â•â•â•â•â•§â•â•â•â•â•â•â•â•â•â•â•â•
```

**Color Coding:**
- Gray (0) - Token absent
- Light Blue (1-2) - Low frequency
- Yellow (3-5) - Medium frequency
- Red (6+) - High frequency

**Controls:**
- â¬…ï¸ **Prev** / **Next** â¡ï¸ - Navigate pages (10 docs/page)
- ğŸ“¥ **Download CSV** - Export full matrix

### Tab 2: ğŸ“– Vocabulary Statistics

**What it shows:** Complete vocabulary with TF-IDF metrics

| Column | Description | Example |
|--------|-------------|---------|
| **ID** | Token index | 15 |
| **Token** | Word (stemmed) | `cleaners` |
| **Doc Freq** | # docs containing token | 35/50 |
| **Avg TF** | Average term frequency | 0.0124 |
| **IDF** | Inverse doc frequency | 1.3507 â–°â–°â–°â–°â–°â–°â–± |
| **Avg TF-IDF** | Average TF-IDF score | 0.0642 â–°â–°â–°â–°â–°â–± |

**Visual Elements:**
- ğŸ“Š **Progress Bars** - Gradient bars showing relative values
- ğŸ¯ **Highlighting** - Yellow background for IDF>1.5 or TF-IDF>0.01
- ğŸ’… **Token Badges** - Monospace font with gray rounded background
- ğŸ”¢ **Monospace Numbers** - Easy comparison and alignment

**Controls:**
- â¬…ï¸ **Prev** / **Next** â¡ï¸ - Navigate pages (50 tokens/page)
- ğŸ“¥ **Download CSV** - Export: `ID,Token,DocFreq,AvgTF,IDF,AvgTF-IDF`

**Example Interpretation:**

```
Token: "cleaners"
Doc Freq: 35    â†’ Appears in 70% of documents
Avg TF: 0.0124  â†’ Average 1.24% of words per document
IDF: 1.3507     â†’ Higher than universal terms (>1.0)
                  â–°â–°â–°â–°â–°â–°â–± (visual bar)
Avg TF-IDF: 0.0642 â†’ HIGHLIGHTED âœ¨ (important term)
                     â–°â–°â–°â–°â–°â–± (visual bar)

Interpretation:
âœ… Moderately common (70% docs)
âœ… Has discriminative power (IDF > 1.0)
âœ… Important for this domain (shopping/cleaning)
```

### Tab 3: ğŸ“„ Documents

**What it shows:** Document comparison (Original vs Preprocessed)

**Features:**
- ğŸ”„ **Toggle View** - Radio buttons to switch between versions
- ğŸ“ **Original Text** - Raw input with formatting preserved
- ğŸ”§ **Preprocessed Text** - Cleaned, lowercased, stemmed tokens
- ğŸ“„ **First 50 Docs** - Pagination for large datasets

**Example:**

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Doc 1                                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  âšª Original  âš« Preprocessed                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Natural Language Processing (NLP) is fascinating â•‘
â•‘  field at the intersection of computer science... â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Click "Preprocessed":
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  natur languag process nlp fascin field          â•‘
â•‘  intersect comput scienc                          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ“¤ Output Files Explained

### 1. `output_sequences.txt` - Detailed Conversion Info

```
Document 1:
-----------
Tokens: [natur, languag, process, nlp, fascin, field, intersect, comput, scienc, ...]
Integer Sequence: [13, 6, 27, 7, 52, 56, 117, 23, 102, ...]

Metadata:
- Original Token Count: 264
- Filtered Token Count: 173
- Unique Tokens: 128
```

**Use case:** Debug preprocessing, verify stemming results

### 2. `output_bow_vectors.txt` - Bag-of-Words

```
Document 1:
-----------
Dimension: 126
Top Features:
  - word: 9
  - text: 5
  - languag: 4
  - process: 4

Sparse Vector: {2: 9, 3: 5, 6: 4, ...}
```

**Use case:** Text classification, document similarity

### 3. `output_tfidf_vectors.txt` - TF-IDF Weighted

```
Document 1:
-----------
L2 Norm: 1.0 (normalized)
Top Features:
  - word: 0.472377
  - text: 0.262432
  - languag: 0.209946

Sparse Vector: {2: 0.472377, 3: 0.262432, ...}
```

**Use case:** Information retrieval, feature selection

### 4. `output_numeric.txt` - ML-Ready Sequences

```
13 6 27 7 52 56 117 23 102 37 30 122 113 ...
```

**Use case:** Feed into neural networks, sequence models

### 5. `report.html` - Interactive Dashboard ğŸŒŸ

**Use case:** Exploratory data analysis, presentation, documentation

**Features:**
- âœ… No server needed - open directly in browser
- âœ… Offline-ready - pure HTML/CSS/JavaScript
- âœ… Responsive - works on desktop, tablet, mobile
- âœ… Modern design - gradient themes, smooth animations
- âœ… Data export - CSV download for Matrix and Vocabulary

---

## ğŸ”§ Pipeline Details

### Stage 1: Text Preprocessing

**Class:** `TextPreprocessor.java`

**Operations:**
1. Lowercase conversion (optional)
2. HTML tag removal
3. URL/email removal
4. Punctuation removal (except apostrophes)
5. Extra whitespace normalization

**Example:**
```
Input:  "Check out https://example.com for NLP! It's amazing."
Output: "check out for nlp it's amazing"
```

### Stage 2: Tokenization

**Class:** `Tokenizer.java`

**Operations:**
1. Split on whitespace and punctuation
2. Filter by minimum length (default: 1)
3. Remove empty tokens

**Example:**
```
Input:  "natural language processing"
Output: ["natural", "language", "processing"]
```

### Stage 3: Stop Word Filtering

**Class:** `StopWordFilter.java`

**127 English Stop Words:**
```
a, an, the, is, are, was, were, be, been, being,
have, has, had, do, does, did, will, would, should,
could, may, might, must, can, of, at, by, for, with,
about, against, between, into, through, during, ...
```

**Example:**
```
Input:  ["natural", "language", "processing", "is", "a", "field"]
Output: ["natural", "language", "processing", "field"]
```

### Stage 4: Porter Stemming

**Class:** `PorterStemmer.java`

**Algorithm:** Porter Stemming (M. Porter, 1980)

**Intelligent Features:**
- âœ… Preserves word meaning (e.g., "program" not "programm")
- âœ… Handles irregular plurals (e.g., "knives" â†’ "knife")
- âœ… Preserves silent-E when needed (e.g., "argue" â†’ "argue")

**Example:**
```
computers â†’ comput
processing â†’ process
languages â†’ languag
running â†’ run
happier â†’ happier (preserved)
```

### Stage 5: Vocabulary Construction

**Class:** `Vocabulary.java`

**Special Tokens:**
- `<PAD>` (Index 0) - Padding token
- `<UNK>` (Index 1) - Unknown token

**Frequency Filtering:**
```
minFrequency = 1  â†’ Keep all tokens
minFrequency = 2  â†’ Only tokens appearing 2+ times
minFrequency = 5  â†’ Only tokens appearing 5+ times
```

**Example:**
```
Vocabulary (128 tokens):
0: <PAD>
1: <UNK>
2: word (freq: 9)
3: text (freq: 5)
4: languag (freq: 4)
...
```

### Stage 6: Integer Encoding

**Class:** `IntegerEncoder.java`

**Mapping:**
```
Token â†’ Index
word â†’ 2
text â†’ 3
languag â†’ 4
unknown_token â†’ 1 (<UNK>)
```

**Example:**
```
Tokens:   ["word", "text", "word", "languag"]
Encoded:  [2, 3, 2, 4]
```

### Stage 7: Vectorization

#### A. Bag-of-Words (BoW)

**Class:** `BagOfWordsVectorizer.java`

**Formula:**
```
BoW[i] = count(token_i in document)
```

**Example:**
```
Document: "word text word languag"
Vocabulary: [word, text, languag, process, ...]

BoW Vector: [2, 1, 1, 0, ...]
            â†‘  â†‘  â†‘  â†‘
          word text lang proc
```

#### B. TF-IDF (Term Frequency-Inverse Document Frequency)

**Class:** `TfidfVectorizer.java`

**Formula (Smooth-IDF):**
```
TF(t,d) = count(t in d) / total_tokens(d)

IDF(t) = log((N + 1) / (df(t) + 1)) + 1
         where N = total documents
               df(t) = documents containing term t

TF-IDF(t,d) = TF(t,d) Ã— IDF(t)

# L2 Normalization:
norm = sqrt(Î£ tfidfÂ²)
normalized_tfidf = tfidf / norm
```

**Example Calculation:**
```
Document: "word text word languag" (4 tokens)
Corpus: 50 documents
Token "word" appears in 40 documents

TF(word) = 2/4 = 0.5

IDF(word) = log((50+1)/(40+1)) + 1
          = log(51/41) + 1
          = log(1.244) + 1
          = 0.218 + 1
          = 1.218

TF-IDF(word) = 0.5 Ã— 1.218 = 0.609

# After L2 normalization across all features:
normalized_tfidf(word) = 0.472377
```

**Verification:** See `TFIDF_VERIFICATION.md`

---

## âš™ï¸ Configuration Guide

### Pipeline Settings

**File:** `src/main/java/com/example/sequencer/core/AutoRunner.java`

```java
PipelineConfiguration config = new PipelineConfiguration()
    .setLowercase(true)              // Convert to lowercase
    .setRemoveStopWords(true)        // Filter stop words
    .setApplyStemming(true)          // Apply Porter stemmer
    .setMinFrequency(1)              // Min word frequency (1 = keep all)
    .setMinTokenLength(1);           // Min token length (1 = keep all)
```

**Parameter Effects:**

| Parameter | Value | Effect |
|-----------|-------|--------|
| `setLowercase` | `true` | "Hello" â†’ "hello" |
| | `false` | "Hello" remains "Hello" |
| `setRemoveStopWords` | `true` | Remove "the", "is", "a", etc. |
| | `false` | Keep all words |
| `setApplyStemming` | `true` | "running" â†’ "run" |
| | `false` | "running" remains "running" |
| `setMinFrequency` | `1` | Keep all tokens (default) |
| | `2` | Only tokens appearing 2+ times |
| | `5` | Only tokens appearing 5+ times |
| `setMinTokenLength` | `1` | Keep all lengths (default) |
| | `2` | Remove single characters |
| | `3` | Only keep words with 3+ chars |

### Document Format

**File:** `DocumentReader.java`

```java
// Option 1: Entire file as one document (default)
DocumentReader.DocumentFormat.SINGLE_DOCUMENT

// Option 2: Each line is a separate document
DocumentReader.DocumentFormat.LINE_PER_DOCUMENT

// Option 3: Blank lines separate documents
DocumentReader.DocumentFormat.PARAGRAPH_PER_DOCUMENT
```

**Example:**

**SINGLE_DOCUMENT:**
```
Line 1: Hello world
Line 2: Natural language processing

Result: 1 document
```

**LINE_PER_DOCUMENT:**
```
Line 1: Hello world
Line 2: Natural language processing

Result: 2 documents
  - Doc 1: "Hello world"
  - Doc 2: "Natural language processing"
```

**PARAGRAPH_PER_DOCUMENT:**
```
Line 1: Hello world
Line 2: This is paragraph one
[blank line]
Line 4: Natural language processing
Line 5: This is paragraph two

Result: 2 documents
  - Doc 1: "Hello world\nThis is paragraph one"
  - Doc 2: "Natural language processing\nThis is paragraph two"
```

---

## ğŸ“š Technical Documentation

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           DocumentSequencerApplication              â”‚
â”‚                  (Entry Point)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SequencingPipeline                     â”‚
â”‚          (7-Stage Orchestrator)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â–¼               â–¼               â–¼               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Preprocessingâ”‚ â”‚  Encoding   â”‚ â”‚Vectorizationâ”‚ â”‚     I/O     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚Preprocessor â”‚ â”‚ Vocabulary  â”‚ â”‚ BoW Vector  â”‚ â”‚ Doc Reader  â”‚
â”‚ Tokenizer   â”‚ â”‚ IntEncoder  â”‚ â”‚ TF-IDF Vec  â”‚ â”‚ Seq Writer  â”‚
â”‚StopWordFilt â”‚ â”‚             â”‚ â”‚             â”‚ â”‚ HTML Writer â”‚
â”‚PorterStemmerâ”‚ â”‚             â”‚ â”‚             â”‚ â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Class Relationships

```mermaid
DocumentSequencerApplication
    â”œâ”€â†’ DocumentReader
    â”œâ”€â†’ SequencingPipeline
    â”‚   â”œâ”€â†’ TextPreprocessor
    â”‚   â”œâ”€â†’ Tokenizer
    â”‚   â”œâ”€â†’ StopWordFilter
    â”‚   â”œâ”€â†’ PorterStemmer
    â”‚   â”œâ”€â†’ Vocabulary
    â”‚   â”œâ”€â†’ IntegerEncoder
    â”‚   â”œâ”€â†’ BagOfWordsVectorizer
    â”‚   â””â”€â†’ TfidfVectorizer
    â”œâ”€â†’ SequenceWriter
    â””â”€â†’ HtmlReportWriter
```

### Data Flow

```
1. Raw Text (String)
   â†“
2. Preprocessed Text (String)
   â†“
3. Tokens (List<String>)
   â†“
4. Filtered Tokens (List<String>)
   â†“
5. Stemmed Tokens (List<String>)
   â†“
6. Integer Sequence (List<Integer>)
   â†“
7a. BoW Vector (Map<Integer, Integer>)
7b. TF-IDF Vector (Map<Integer, Double>)
```

### Performance Considerations

**Memory Usage:**
- Vocabulary: O(V) where V = unique tokens
- BoW Vector: O(V) sparse representation
- TF-IDF Vector: O(V) sparse representation
- HTML Report: ~3MB for 50 documents, 377 tokens

**Time Complexity:**
- Preprocessing: O(n) where n = text length
- Tokenization: O(n)
- Stop Word Filtering: O(t) where t = token count
- Stemming: O(t Ã— k) where k = avg token length
- Vocabulary Building: O(t)
- Encoding: O(t)
- BoW Vectorization: O(t)
- TF-IDF Vectorization: O(t Ã— d) where d = document count

**Scalability:**
- âœ… 1-50 documents: Excellent performance
- âœ… 50-100 documents: Good performance
- âš ï¸ 100+ documents: Consider pagination optimization
- ğŸ’¡ 1000+ documents: Use batch processing with chunking

---

## â“ FAQ & Troubleshooting

### General Questions

**Q: What Java version do I need?**
- A: Java 11 or higher. Check with `java -version`

**Q: Can I process multiple documents at once?**
- A: Yes! Use batch mode: `.\build.bat auto` with multiple `.txt` files in `Data/Input/`

**Q: How do I customize preprocessing?**
- A: Edit `AutoRunner.java` lines 49-54 to change `PipelineConfiguration` settings

**Q: Why are there different token indices in different outputs?**
- A: 
  - `Vocabulary` uses 0=<PAD>, 1=<UNK>, 2+=tokens
  - `BoW/TF-IDF` use 0-based indices of unique tokens only

**Q: What's the difference between BoW and TF-IDF?**
- A:
  - **BoW**: Raw counts (e.g., "word" appears 9 times)
  - **TF-IDF**: Weighted by importance (rare words get higher scores)

### TF-IDF Questions

**Q: How is IDF calculated?**
- A: `IDF(t) = log((N+1)/(df+1)) + 1` (smooth-idf, sklearn standard)
- See `TFIDF_VERIFICATION.md` for detailed explanation

**Q: Why is my TF-IDF different from online calculators?**
- A: Different formulas exist:
  - **This tool**: `log((N+1)/(df+1)) + 1` + L2 normalization
  - **Standard**: `log(N/df)`
  - **Smooth**: `log(N/(df+1)) + 1`
  - Our implementation matches **sklearn's default**

**Q: What does "Doc Freq" mean in the Vocabulary table?**
- A: Number of documents containing that token (out of total N documents)

**Q: Why is IDF highlighted in yellow?**
- A: IDF > 1.5 indicates a relatively rare term with discriminative power

### HTML Report Questions

**Q: How do I view the HTML report?**
- A: Simply double-click `Data/Output/report.html` to open in your browser

**Q: The tabs are not switching!**
- A: Make sure JavaScript is enabled in your browser

**Q: Can I share the HTML report?**
- A: Yes! It's a standalone file with no external dependencies

**Q: The table is too wide to view**
- A: Use horizontal scroll bar, or zoom out in browser (Ctrl + Mouse Wheel)

**Q: How do I export data from the HTML?**
- A: Click "ğŸ“¥ Download CSV" button in Matrix or Vocabulary tabs

### Build/Compilation Issues

**Q: `javac: command not found`**
- A: Java not in PATH. Add Java bin folder to system PATH environment variable

**Q: `Error: Could not find or load main class`**
- A: Run `.\build.bat` first to compile before running

**Q: `src\main\java\...: error: unmappable character for encoding UTF-8`**
- A: Save Java files with UTF-8 encoding (not UTF-8 with BOM)

**Q: Files are not being processed**
- A: Check that:
  1. Files are in `Data/Input/` folder
  2. Files have `.txt` extension
  3. Files contain text (not empty)

### Performance Issues

**Q: HTML report is slow with many documents**
- A: This is normal with 100+ documents. Use pagination controls to navigate

**Q: Build takes too long**
- A: First build compiles everything. Subsequent builds are incremental and faster

**Q: Out of memory error**
- A: Increase Java heap: `java -Xmx2g -cp ...` or reduce document count

### Output Interpretation

**Q: Why do some tokens have IDF = 1.00?**
- A: Token appears in ALL documents, so IDF is minimum (log((N+1)/(N+1))+1 = 1.0)

**Q: What's a good TF-IDF score?**
- A: Depends on corpus, but generally:
  - 0.00-0.01: Low importance (common words)
  - 0.01-0.05: Medium importance
  - 0.05+: High importance (rare & frequent)

**Q: Why are BoW counts different from TF-IDF values?**
- A: TF-IDF applies:
  1. Term frequency normalization (TF)
  2. Inverse document frequency weighting (IDF)
  3. L2 vector normalization

---

## ğŸ“ References & Citations

### Scientific Papers
1. **Porter, M. F.** (1980). "An algorithm for suffix stripping." _Program_, 14(3), 130-137.
2. **Salton, G., & Buckley, C.** (1988). "Term-weighting approaches in automatic text retrieval." _Information Processing & Management_, 24(5), 513-523.

### Online Resources
1. [GeeksforGeeks - Understanding TF-IDF](https://www.geeksforgeeks.org/understanding-tf-idf-term-frequency-inverse-document-frequency/)
2. [GeeksforGeeks - Bag of Words Model](https://www.geeksforgeeks.org/bag-of-words-bow-model-in-nlp/)
3. [Wikipedia - TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)
4. [Sklearn TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)

### Implementation Standards
- TF-IDF formula matches **sklearn's smooth-idf** default
- Porter Stemming follows **original 1980 algorithm**
- Stop words list based on **NLTK English stopwords**

---

## ğŸ“ Version History

### v2.0 (Current) - Enhanced UI & Verified TF-IDF
- âœ¨ Modern animated tab design with icons
- ğŸ“Š Visual progress bars for IDF/TF-IDF values
- ğŸ¯ Smart highlighting for important terms
- ğŸ“– 6-column Vocabulary table (added Doc Freq)
- âœ… Fixed TF-IDF calculation (smooth-idf formula)
- ğŸ“š Complete documentation (3 MD files)
- ğŸ¨ Professional styling (gradient, shadows, animations)
- ğŸ“¥ CSV export with 6 columns
- ğŸ”§ Batch processing for 50+ files

### v1.0 - Initial Release
- ğŸš€ 7-stage NLP pipeline
- ğŸ“Š Basic HTML report
- ğŸ“ˆ BoW and TF-IDF vectorization
- ğŸ”§ Interactive and auto modes

---

## ğŸ¤ Contributing

Want to extend this project? Consider adding:

### Feature Ideas
- ğŸŒ **Multilingual Support** - Support for non-English languages
- ğŸ”¤ **Lemmatization** - Alternative to stemming (preserve word meaning)
- ğŸ“Š **N-grams** - Bigrams, trigrams for phrase detection
- ğŸ§  **Word Embeddings** - Word2Vec, GloVe, FastText integration
- ğŸ¤– **BERT Embeddings** - Transformer-based representations
- ğŸ“ˆ **Visualization** - Word clouds, t-SNE plots, PCA
- ğŸ” **Search Engine** - Query and rank documents by relevance
- ğŸ“Š **Clustering** - K-means, hierarchical clustering
- ğŸ·ï¸ **Classification** - Naive Bayes, SVM, Neural Networks
- ğŸ“± **Web API** - REST API for text processing

### Code Improvements
- âœ… Unit tests (JUnit)
- âœ… Maven/Gradle build
- âœ… Docker containerization
- âœ… CI/CD pipeline
- âœ… Performance benchmarks
- âœ… Logging framework (SLF4J)
- âœ… Configuration files (YAML/JSON)

---

## ğŸ“„ License

**MIT License** - Free for educational and research purposes

```
Copyright (c) 2025 DocumentToSequences Project

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
```

---

## ğŸ™ Acknowledgments

- **GeeksforGeeks** - Excellent NLP tutorials and TF-IDF explanations
- **Martin Porter** - Porter Stemming algorithm (1980)
- **Scikit-learn** - TF-IDF implementation reference
- **NLTK** - English stop words list
- **Wikipedia** - TF-IDF formula verification

---

## ğŸ“ Support

### Getting Help
1. ğŸ“– Read this README thoroughly
2. ğŸ“š Check `TFIDF_VERIFICATION.md` for TF-IDF details
3. ğŸ“‹ Review `VOCAB_TABLE_GUIDE.txt` for quick reference
4. ğŸŒ Open `Data/Output/report.html` for visual analysis

### Reporting Issues
When reporting bugs, please include:
- Java version (`java -version`)
- Operating system
- Input file sample
- Error message / stack trace
- Console output

---

## ğŸš€ Quick Command Reference

```bash
# Windows
.\build.bat              # Build only
.\build.bat run          # Interactive mode
.\build.bat auto         # Batch processing + HTML report â­
.\build.bat test         # Run tests

# Linux/Mac
./build.sh               # Build only
./build.sh run           # Interactive mode
./build.sh auto          # Batch processing + HTML report â­
./build.sh test          # Run tests

# View Results
# Open: Data/Output/report.html in browser ğŸŒ
```

---

<div align="center">

### ğŸŒŸ Star this project if you found it helpful! ğŸŒŸ

**Built with â¤ï¸ for the NLP community**

---

**[ğŸ“Š View Demo](Data/Output/report.html)** â€¢ 
**[ğŸ“š Documentation](TFIDF_VERIFICATION.md)** â€¢ 
**[ğŸ› Report Bug](issues)** â€¢ 
**[ğŸ’¡ Request Feature](issues)**

---

**Happy Text Mining! ğŸš€ğŸ“Šâœ¨**

</div>
