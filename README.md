# ğŸ“Š Document-to-Sequence Converter

> **Research-Grade NLP Implementation for Data Mining & Text Vectorization**

[![Java](https://img.shields.io/badge/Java-8+-orange.svg)](https://www.oracle.com/java/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Build](https://img.shields.io/badge/Build-Maven-red.svg)](pom.xml)
[![Status](https://img.shields.io/badge/Status-Production-brightgreen.svg)]()

---

## ğŸ“‹ Table of Contents

- [ğŸ¯ Overview](#-overview)
- [âœ¨ Features](#-features)
- [ğŸ—ï¸ Architecture](#ï¸-architecture)
- [ğŸš€ Quick Start](#-quick-start)
- [ğŸ“– Usage Guide](#-usage-guide)
- [ğŸ”¬ Technical Details](#-technical-details)
- [ğŸ“Š Output Formats](#-output-formats)
- [ğŸ§ª Example Workflow](#-example-workflow)
- [ğŸ“š Documentation](#-documentation)
- [ğŸ¤ Contributing](#-contributing)

---

## ğŸ¯ Overview

**Document-to-Sequence Converter** is a comprehensive Java implementation of state-of-the-art Natural Language Processing (NLP) techniques for transforming unstructured text documents into numerical sequences suitable for machine learning and data mining applications.

### ğŸ“ Academic Foundation

This project implements methodologies documented in academic research and industry best practices:

- **Bag-of-Words (BoW)** - Frequency-based sparse vector representation
- **TF-IDF** - Statistical measure of word importance across documents
- **Text Preprocessing Pipeline** - Industry-standard cleaning and normalization
- **Porter Stemming** - Morphological word reduction
- **Integer Encoding** - Vocabulary-based sequence generation

### ğŸ¯ Use Cases

- ğŸ“ˆ **Text Classification** - Categorize documents by topic or sentiment
- ğŸ” **Information Retrieval** - Search engines and document ranking
- ğŸ¤– **Machine Learning Pipelines** - Feature extraction for ML models
- ğŸ“Š **Data Mining** - Pattern discovery in text corpora
- ğŸ§  **Research & Education** - Learning NLP fundamentals

---

## âœ¨ Features

### ğŸ”§ Text Preprocessing Pipeline

| Feature | Description | Configuration |
|---------|-------------|---------------|
| **HTML Tag Removal** | Strip HTML markup from web-scraped content | âœ… Enabled by default |
| **URL Removal** | Eliminate web addresses and links | âœ… Enabled by default |
| **Email Removal** | Remove email addresses | âœ… Enabled by default |
| **Case Normalization** | Convert to lowercase | âš™ï¸ Configurable |
| **Stop Word Filtering** | Remove common words (a, the, is, etc.) | âš™ï¸ Configurable |
| **Porter Stemming** | Reduce words to root form (running â†’ run) | âš™ï¸ Configurable |
| **Punctuation Removal** | Clean non-alphanumeric characters | âœ… Enabled by default |

### ğŸ¨ Vectorization Methods

#### 1ï¸âƒ£ **Integer Encoding**
- Maps each unique word to a numerical index
- Creates vocabulary from corpus
- Generates ordered sequences of integers
- Supports minimum frequency filtering
- Handles out-of-vocabulary (OOV) words with `<UNK>` token

#### 2ï¸âƒ£ **Bag-of-Words (BoW)**
- Word frequency counting per document
- Sparse vector representation
- Configurable binary mode (presence/absence)
- Efficient storage for high-dimensional vectors

#### 3ï¸âƒ£ **TF-IDF Vectorization**

**Multiple TF (Term Frequency) Formulas:**
| Formula | Description | Mathematical Expression |
|---------|-------------|------------------------|
| Binary | Presence indicator | `1 if t âˆˆ d else 0` |
| Raw Count | Simple frequency | `f(t,d)` |
| Term Frequency | Normalized by document length | `f(t,d) / Î£f(t',d)` |
| Log Normalization | Logarithmic scaling | `log(1 + f(t,d))` |
| Double Norm 0.5 | Bias prevention | `0.5 + 0.5 Ã— f(t,d) / max{f(t',d)}` |
| Double Norm K | Parameterized normalization | `K + (1-K) Ã— f(t,d) / max{f(t',d)}` |

**Multiple IDF (Inverse Document Frequency) Formulas:**
| Formula | Description | Mathematical Expression |
|---------|-------------|------------------------|
| Unary | No weighting | `1` |
| IDF | Standard inverse frequency | `log(N / n(t))` |
| IDF Smooth | Smoothed version | `log((N+1) / (n(t)+1)) + 1` |
| IDF Max | Maximum-based | `log(max{n(t')} / n(t))` |
| IDF Probabilistic | Probability-based | `log((N - n(t)) / n(t))` |

### ğŸ“Š Advanced Features

- **ğŸ”„ Batch Processing** - Process entire folders of documents
- **ğŸ“ˆ HTML Reports** - Beautiful interactive visualization
- **ğŸ’¾ Multiple Output Formats** - Plain text, CSV, JSON-compatible
- **ğŸ¯ Smart Configuration** - Auto-discovery with manual override
- **ğŸ“± Responsive UI** - Professional HTML/CSS reporting
- **âš¡ Performance Optimized** - Efficient sparse matrix operations

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOCUMENT INPUT LAYER                     â”‚
â”‚  ğŸ“„ Raw Text â€¢ HTML Content â€¢ File System â€¢ Batch Input     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â¬‡ï¸
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              TEXT PREPROCESSING PIPELINE                    â”‚
â”‚  ğŸ§¹ Clean â†’ ğŸ”¤ Normalize â†’ âœ‚ï¸ Tokenize â†’ ğŸš« Filter        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â¬‡ï¸
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                LINGUISTIC PROCESSING                        â”‚
â”‚  ğŸ“š Stop Word Removal â†’ ğŸŒ± Porter Stemming                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â¬‡ï¸
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ENCODING & VECTORIZATION                       â”‚
â”‚  ğŸ”¢ Integer Encoding â€¢ ğŸ‘œ Bag-of-Words â€¢ ğŸ“Š TF-IDF         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â¬‡ï¸
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   OUTPUT GENERATION                         â”‚
â”‚  ğŸ’¾ Sequences â€¢ ğŸ“Š Vectors â€¢ ğŸ“ˆ Reports â€¢ ğŸ“‰ Statistics   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ“¦ Package Structure

```
src/main/java/com/example/sequencer/
â”œâ”€â”€ ğŸ¯ core/                          # Main applications
â”‚   â”œâ”€â”€ DocumentSequencerApplication  # Interactive console app
â”‚   â””â”€â”€ AutoRunner                    # Batch processing mode
â”œâ”€â”€ ğŸ”§ preprocessing/                 # Text cleaning
â”‚   â”œâ”€â”€ TextPreprocessor             # HTML, URL, email removal
â”‚   â”œâ”€â”€ Tokenizer                    # Word splitting
â”‚   â”œâ”€â”€ StopWordFilter               # Common word removal
â”‚   â””â”€â”€ PorterStemmer               # Morphological analysis
â”œâ”€â”€ ğŸ”¢ encoding/                      # Sequence generation
â”‚   â”œâ”€â”€ Vocabulary                   # Word-to-index mapping
â”‚   â””â”€â”€ IntegerEncoder              # Sequence encoder
â”œâ”€â”€ ğŸ“Š vectorization/                 # Vector representations
â”‚   â”œâ”€â”€ BagOfWordsVectorizer        # BoW implementation
â”‚   â”œâ”€â”€ TfidfVectorizer             # TF-IDF implementation
â”‚   â”œâ”€â”€ TFIDFCalculator             # All formula calculator
â”‚   â”œâ”€â”€ TFFormula                   # TF formula enums
â”‚   â””â”€â”€ IDFFormula                  # IDF formula enums
â”œâ”€â”€ ğŸ¨ io/                            # Input/Output handlers
â”‚   â”œâ”€â”€ DocumentReader              # File reading
â”‚   â”œâ”€â”€ SequenceWriter              # Results writing
â”‚   â””â”€â”€ HTMLReportWriter            # Report generation
â”œâ”€â”€ ğŸ—ï¸ pipeline/                      # Workflow orchestration
â”‚   â””â”€â”€ SequencingPipeline          # End-to-end processing
â”œâ”€â”€ ğŸ“¦ model/                         # Data models
â”‚   â”œâ”€â”€ DocumentSequence            # Document representation
â”‚   â””â”€â”€ SequenceVector              # Vector representation
â””â”€â”€ ğŸ› ï¸ utils/                         # Utility functions
    â””â”€â”€ MathUtils                   # Mathematical operations
```

---

## ğŸš€ Quick Start

### âš¡ Prerequisites

- â˜• **Java 8+** - [Download JDK](https://www.oracle.com/java/technologies/downloads/)
- ğŸ“¦ **Maven** (optional) - For dependency management
- ğŸ’» **Command Line** - Terminal/PowerShell/CMD

### ğŸ¯ Installation

#### **Option 1: Using Build Scripts (Recommended)**

**Windows:**
```powershell
# Clone or download the repository
cd Documents-To-Sequences-main

# Build the project
.\build.bat

# Run interactive mode
.\build.bat run

# Run batch mode with HTML report
.\build.bat auto
```

**Linux/Mac:**
```bash
# Clone or download the repository
cd Documents-To-Sequences-main

# Make script executable
chmod +x build.sh

# Build the project
./build.sh

# Run interactive mode
./build.sh run

# Run batch mode with HTML report
./build.sh auto
```

#### **Option 2: Using Maven**

```bash
# Build project
mvn clean compile

# Run application
mvn exec:java -Dexec.mainClass="com.example.sequencer.core.DocumentSequencerApplication"

# Run auto mode
mvn exec:java -Dexec.mainClass="com.example.sequencer.core.AutoRunner"
```

#### **Option 3: Manual Compilation**

```bash
# Compile
javac -d target/classes -encoding UTF-8 src/main/java/com/example/sequencer/**/*.java

# Run
java -cp target/classes com.example.sequencer.core.DocumentSequencerApplication
```

---

## ğŸ“– Usage Guide

### ğŸ® Interactive Mode

Perfect for **single-file processing** and **experimentation**:

```bash
.\build.bat run
```

**Step-by-Step Workflow:**

1. **ğŸ“ Select Input Mode**
   ```
   1. Single input file
   2. Entire folder (all .txt files)
   ```

2. **ğŸ“„ Choose Document Format**
   ```
   1. Single Document (entire file)
   2. Line per Document
   3. Paragraph per Document
   ```

3. **âš™ï¸ Configure Pipeline**
   ```
   Press ENTER for defaults or 'custom' for manual configuration
   ```

4. **ğŸ¯ Custom Configuration Options**
   - Convert to lowercase? (y/n)
   - Remove stop words? (y/n)
   - Apply Porter stemming? (y/n)
   - Minimum word frequency (default: 1)
   - Minimum token length (default: 1)

5. **ğŸ“Š View Results**
   - Sequences written to `Data/Output/output_sequences.txt`
   - BoW vectors â†’ `Data/Output/output_bow_vectors.txt`
   - TF-IDF vectors â†’ `Data/Output/output_tfidf_vectors.txt`
   - HTML Report â†’ `Data/Output/output_report.html`

### ğŸ”„ Batch Processing Mode

Ideal for **processing multiple documents** with **HTML visualization**:

```bash
.\build.bat auto
```

**Features:**
- âœ… Automatically processes all `.txt` files in `Data/Input/`
- âœ… Generates comprehensive HTML report
- âœ… Produces all output formats
- âœ… No user interaction required
- âœ… Perfect for scheduled jobs

**Output Files:**
```
Data/Output/
â”œâ”€â”€ output_sequences.txt       # Integer-encoded sequences
â”œâ”€â”€ output_bow_vectors.txt     # Bag-of-Words vectors
â”œâ”€â”€ output_tfidf_vectors.txt   # TF-IDF with all formulas
â”œâ”€â”€ output_numeric.txt         # Pure numeric sequences (ML-ready)
â””â”€â”€ report.html                # Interactive visualization ğŸŒŸ
```

### ğŸ“Š HTML Report Features

The generated HTML report includes:

#### ğŸ¨ **Interactive Tabs**
- **ğŸ“Š Frequency Matrix** - Term-document frequency table
- **ğŸ“– Vocabulary** - Word statistics and IDF scores
- **ğŸ“„ Documents** - Original vs. preprocessed comparison

#### ğŸ” **Features**
- âœ¨ Responsive design with gradient styling
- ğŸ“± Mobile-friendly layout
- ğŸ“¥ CSV download capability
- â­ï¸ Pagination for large datasets
- ğŸ¯ Visual frequency indicators (bar charts)
- ğŸ”„ Toggle between original and preprocessed text
- ğŸ“ˆ Summary statistics dashboard

#### ğŸ¯ **Statistics Display**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Documents   â”‚ Vocabulary   â”‚ Tokens     â”‚
â”‚     50      â”‚     377      â”‚   22,692   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¬ Technical Details

### ğŸ§® TF-IDF Implementation

This implementation provides **30 different TF-IDF combinations** (6 TF formulas Ã— 5 IDF formulas), allowing comprehensive analysis of text importance.

#### **Example: Standard TF-IDF Calculation**

**Input Document:** `"the cat sat on the mat"`

**Step 1: Term Frequency (TF)**
```
Term    | Count | TF (normalized)
--------|-------|----------------
the     |   2   |  2/6 = 0.333
cat     |   1   |  1/6 = 0.167
sat     |   1   |  1/6 = 0.167
on      |   1   |  1/6 = 0.167
mat     |   1   |  1/6 = 0.167
```

**Step 2: Inverse Document Frequency (IDF)**
```
Given: 10 total documents
Term "the" appears in 8 documents
Term "cat" appears in 3 documents

IDF("the") = log(10/8) = 0.097
IDF("cat") = log(10/3) = 0.522
```

**Step 3: TF-IDF Score**
```
TF-IDF("the") = 0.333 Ã— 0.097 = 0.032 (common word)
TF-IDF("cat") = 0.167 Ã— 0.522 = 0.087 (more important)
```

### ğŸ“Š Vectorization Comparison

| Feature | BoW | TF-IDF | Integer Encoding |
|---------|-----|--------|------------------|
| **Vector Type** | Sparse | Sparse | Sequential |
| **Dimensionality** | Vocabulary Size | Vocabulary Size | Variable Length |
| **Word Order** | âŒ Lost | âŒ Lost | âœ… Preserved |
| **Word Importance** | Equal weight | Weighted | N/A |
| **Use Case** | Classification | Information Retrieval | Neural Networks |
| **Memory** | Medium | Medium | Low |

### ğŸ›¡ï¸ Porter Stemming Examples

```
Original    â†’  Stemmed
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
running     â†’  run
computers   â†’  comput
beautiful   â†’  beauti
connection  â†’  connect
studying    â†’  studi
```

**Smart Features:**
- âœ… Protects protected words (brand names, acronyms)
- âœ… Preserves known words to avoid over-stemming
- âœ… Configurable enable/disable

---

## ğŸ“Š Output Formats

### 1ï¸âƒ£ **Integer Sequences** (`output_sequences.txt`)

```
Document #1: [45, 123, 67, 89, 12, 45, 90]
Document #2: [23, 56, 78, 12, 90, 34]
Document #3: [89, 90, 12, 45, 67, 123]

Vocabulary Mapping:
0: <PAD>
1: <UNK>
12: the
23: cat
34: sat
...
```

### 2ï¸âƒ£ **Bag-of-Words Vectors** (`output_bow_vectors.txt`)

```
Document #1 - BoW Vector (Sparse)
  Index    Token          Count
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    12     the              2
    45     cat              1
    67     sat              1
    89     on               1
    90     mat              1

Vector dimension: 377
Non-zero elements: 5
Sparsity: 98.67%
```

### 3ï¸âƒ£ **TF-IDF Vectors** (`output_tfidf_vectors.txt`)

```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Document #1 - TF-IDF Analysis
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘           TERM FREQUENCY (TF) FORMULAS                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Formula: TERM_FREQUENCY = f(t,d) / Î£f(t',d)

  Token          Count    TF Value
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  the              2      0.333
  cat              1      0.167
  sat              1      0.167
  ...

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     INVERSE DOCUMENT FREQUENCY (IDF) FORMULAS          â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Formula: IDF_SMOOTH = log((N+1) / (n(t)+1)) + 1

  Token      Doc Freq    IDF Value
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  the           45       1.105
  cat           12       2.234
  sat            8       2.526
  ...

â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘              TF-IDF FINAL SCORES                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

  Token          TF-IDF Score
  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  cat              0.373
  sat              0.422
  the              0.368
  ...
```

### 4ï¸âƒ£ **Numeric Sequences** (`output_numeric.txt`)

**ML-Ready Format** - Direct input for neural networks:

```
45 123 67 89 12 45 90
23 56 78 12 90 34
89 90 12 45 67 123
```

### 5ï¸âƒ£ **HTML Report** (`report.html`)

Interactive web-based visualization - **open in any browser!**

---

## ğŸ§ª Example Workflow

### ğŸ“ Complete Processing Example

**Input Files:**
```
Data/Input/
â”œâ”€â”€ review1.txt  "The product quality is excellent!"
â”œâ”€â”€ review2.txt  "Poor quality, not recommended."
â””â”€â”€ review3.txt  "Excellent product, highly recommended!"
```

**Execution:**
```bash
.\build.bat auto
```

**Pipeline Processing:**

```
[1/7] Text Preprocessing...
  âœ“ HTML tags removed
  âœ“ Lowercase conversion
  âœ“ Punctuation cleaned

[2/7] Tokenization...
  âœ“ Generated 18 tokens

[3/7] Stop Word Filtering...
  âœ“ Retained 12 tokens

[4/7] Stemming...
  âœ“ Applied Porter Stemmer
  â€¢ quality â†’ qualiti
  â€¢ excellent â†’ excel
  â€¢ recommended â†’ recommend

[5/7] Vocabulary Construction...
  âœ“ Vocabulary size: 7 unique terms

[6/7] Bag-of-Words Vectorization...
  âœ“ Generated BoW vectors

[7/7] TF-IDF Vectorization...
  âœ“ Generated TF-IDF vectors
```

**Vocabulary Built:**
```
Index | Token      | Document Frequency
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  0   | product    | 2
  1   | qualiti    | 2
  2   | excel      | 2
  3   | poor       | 1
  4   | recommend  | 2
  5   | high       | 1
```

**Integer Sequences:**
```
Document 1: [0, 1, 2]           # product quality excellent
Document 2: [3, 1, 4]           # poor quality recommend
Document 3: [2, 0, 5, 4]        # excellent product highly recommend
```

**TF-IDF Insights:**
- â­ **"poor"** has highest TF-IDF in Doc 2 (unique discriminator)
- â­ **"excel"** is important but appears in 2 docs (moderate weight)
- â­ **"product"** common across docs (lower weight)

---

## ğŸ“š Documentation

### ğŸ“– Additional Resources

| Document | Description |
|----------|-------------|
| [`TFIDF-VERIFICATION.md`](TFIDF-VERIFICATION.md) | ğŸ”¬ Complete TF-IDF formula verification guide |
| [`Document-to-Sequence Conversion in Data Mining.txt`](Document-to-Sequence%20Conversion%20in%20Data%20Mining.txt) | ğŸ“š Comprehensive research documentation |
| [Source Code JavaDoc](src/main/java/) | ğŸ’» Inline API documentation |

### ğŸ“ Academic References

This implementation is based on established NLP literature:

1. **Porter Stemmer Algorithm** - Porter, M.F. (1980)
2. **TF-IDF** - Salton, G. & McGill, M. (1983)
3. **Bag-of-Words Model** - Harris, Z. (1954)
4. **Text Preprocessing** - Manning & SchÃ¼tze (1999)

### ğŸ”— External References

- [TF-IDF Wikipedia](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)
- [Porter Stemming Algorithm](https://tartarus.org/martin/PorterStemmer/)
- [Text Vectorization Guide](https://scikit-learn.org/stable/modules/feature_extraction.html)

---

## ğŸ¯ Configuration Reference

### Pipeline Configuration Options

```java
PipelineConfiguration config = new PipelineConfiguration()
    .setLowercase(true)              // Convert to lowercase
    .setRemoveStopWords(true)        // Filter common words
    .setApplyStemming(true)          // Apply Porter stemmer
    .setMinFrequency(1)              // Minimum word frequency
    .setMinTokenLength(1);           // Minimum token length
```

### Document Format Options

| Format | Description | Use Case |
|--------|-------------|----------|
| `SINGLE_DOCUMENT` | Entire file as one document | Books, articles |
| `LINE_PER_DOCUMENT` | Each line is a document | Reviews, tweets |
| `PARAGRAPH_PER_DOCUMENT` | Each paragraph is a document | Essays, reports |

---

## ğŸ› ï¸ Troubleshooting

### Common Issues

**âŒ Compilation Error: `javac: command not found`**
```bash
# Solution: Install JDK 8+ and add to PATH
# Windows: Set JAVA_HOME environment variable
# Linux/Mac: export JAVA_HOME=/path/to/jdk
```

**âŒ OutOfMemoryError for large datasets**
```bash
# Solution: Increase heap size
java -Xmx4g -cp target/classes com.example.sequencer.core.AutoRunner
```

**âŒ UnsupportedEncodingException**
```bash
# Solution: Ensure UTF-8 encoding
javac -encoding UTF-8 ...
```

**âŒ Empty output files**
- âœ… Check input file encoding (must be UTF-8)
- âœ… Verify input folder path
- âœ… Ensure input files are not empty
- âœ… Check file permissions

---

## ğŸš€ Performance Tips

### âš¡ Optimization Strategies

1. **Batch Processing**: Use `AutoRunner` for multiple files
2. **Memory Management**: Adjust JVM heap size for large corpora
3. **Preprocessing**: Disable unnecessary steps for speed
4. **Vocabulary Size**: Use `minFrequency` to reduce dimensionality
5. **Stop Words**: Remove them early to reduce processing time

### ğŸ“Š Benchmarks

| Corpus Size | Documents | Vocab | Processing Time |
|-------------|-----------|-------|----------------|
| Small | 10 | 500 | < 1s |
| Medium | 100 | 5,000 | 2-5s |
| Large | 1,000 | 50,000 | 10-30s |
| Very Large | 10,000 | 100,000 | 1-3min |

*Tested on Intel i7, 16GB RAM*

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

### ğŸ› Bug Reports
- Use GitHub Issues
- Include Java version, OS, and error logs
- Provide minimal reproducible example

### âœ¨ Feature Requests
- Describe use case and benefits
- Check existing issues first
- Consider implementation complexity

### ğŸ’» Code Contributions
1. Fork the repository
2. Create feature branch (`git checkout -b feature/AmazingFeature`)
3. Follow existing code style
4. Add JavaDoc comments
5. Test thoroughly
6. Submit pull request

---

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¥ Authors

**Research Implementation Team**
- Comprehensive NLP Pipeline Design
- TF-IDF Multi-Formula Implementation
- HTML Report Visualization

---

## ğŸ™ Acknowledgments

- Porter Stemmer algorithm by Martin Porter
- Stop words list from NLTK project
- TF-IDF formulas from Wikipedia
- Inspired by scikit-learn's text vectorization

---

## ğŸ“ Support

- ğŸ“§ **Email**: Open an issue on GitHub
- ğŸ’¬ **Discussions**: GitHub Discussions
- ğŸ“– **Documentation**: See `docs/` folder
- ğŸ› **Bug Reports**: GitHub Issues

---

## ğŸ“ Citation

If you use this software in your research, please cite:

```bibtex
@software{document_to_sequence_converter,
  title = {Document-to-Sequence Converter for Data Mining},
  author = {Research Implementation Team},
  year = {2025},
  version = {1.0},
  url = {https://github.com/yourusername/Documents-To-Sequences}
}
```

---

<div align="center">

### â­ Star this repository if you find it helpful!

**Made with â¤ï¸ for the NLP & Data Mining Community**

[â¬† Back to Top](#-document-to-sequence-converter)

</div>
